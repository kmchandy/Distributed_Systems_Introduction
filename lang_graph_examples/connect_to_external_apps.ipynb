{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9faf7c1e",
   "metadata": {},
   "source": [
    "# ðŸŒ LangGraph Example: Travel Assistant with Weather & Historical Fact\n",
    "\n",
    "This notebook demonstrates a LangGraph-based multi-agent assistant that:\n",
    "\n",
    "- Accepts a user query (e.g., \"I'm going to Paris\")\n",
    "- Extracts a city name\n",
    "- Fetches weather data from Open-Meteo API\n",
    "- Retrieves a fact from Wikipedia\n",
    "- Summarizes both using an LLM\n",
    "\n",
    "It uses real external APIs and demonstrates LangGraphâ€™s modular workflow structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10ffb139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Install required packages\n",
    "!pip install -q langchain openai langgraph requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b4c8b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Check that the key is loaded\n",
    "assert os.getenv(\"OPENAI_API_KEY\") is not None, \"OPENAI_API_KEY is not set\"\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize LLM using env key\n",
    "llm = ChatOpenAI(temperature=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85f5e8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Define state schema\n",
    "from typing import TypedDict\n",
    "\n",
    "class State(TypedDict):\n",
    "    user_query: str\n",
    "    city: str\n",
    "    weather: str\n",
    "    fact: str\n",
    "    final_summary: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a25834f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸŒ External API tools\n",
    "import requests\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    geo = requests.get(f\"https://nominatim.openstreetmap.org/search?format=json&q={city}\",\n",
    "                       headers={\"User-Agent\": \"langchain-agent\"}).json()\n",
    "    lat, lon = geo[0][\"lat\"], geo[0][\"lon\"]\n",
    "    weather = requests.get(\n",
    "        f\"https://api.open-meteo.com/v1/forecast?latitude={lat}&longitude={lon}&current_weather=true\"\n",
    "    ).json()\n",
    "    temp = weather[\"current_weather\"][\"temperature\"]\n",
    "    return f\"The current temperature in {city} is {temp}Â°C.\"\n",
    "\n",
    "def get_fact(city: str) -> str:\n",
    "    city_url = city.replace(\" \", \"_\")\n",
    "    r = requests.get(\n",
    "        f\"https://en.wikipedia.org/api/rest_v1/page/summary/{city_url}\"\n",
    "    )\n",
    "    if r.status_code != 200:\n",
    "        return f\"No Wikipedia summary found for {city}\"\n",
    "    return r.json().get(\"extract\", \"No summary available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "711ab124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ¤– Node functions\n",
    "\n",
    "def extract_city(state: State) -> dict:\n",
    "    user_query = state[\"user_query\"]\n",
    "    if not user_query:\n",
    "        raise ValueError(\"User query is required.\")\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    You are a helpful assistant who can understand complex and \n",
    "    ill-formed queries. Return the following two pieces of\n",
    "    information \"city\" and \"fact\" from {user_query}.\n",
    "    1. Extract the city or town name from the query: \n",
    "    If no city or town is mentioned, return \"Unknown\". \n",
    "    If more than one city is mentioned, return the first one.\n",
    "    2. Extract a question about the city from the query. Examples\n",
    "    of a question are: \"What museums are open?\" and \"What is a fun fact?\"\n",
    "\n",
    "    Return a JSON object like this:\n",
    "    {{\n",
    "    \"city\": \"<city name or Unknown>\",\n",
    "    \"fact\": \"<question about the city or Unknown>\"\n",
    "    }}\n",
    "\n",
    "    Rules:\n",
    "    - If no city is found, use \"Unknown\"\n",
    "    - If no question is found, use \"Unknown\"\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Send prompt to LLM\n",
    "    response = llm.invoke(prompt).content.strip()\n",
    "\n",
    "    try:\n",
    "        parsed = json.loads(response)\n",
    "    except json.JSONDecodeError:\n",
    "        raise ValueError(f\"Could not parse response: {response}\")\n",
    "\n",
    "    city = parsed.get(\"city\", \"Unknown\")\n",
    "    fact = parsed.get(\"fact\", \"Unknown\")\n",
    "    print(f\"Extracted city: {city}, fact: {fact}\")\n",
    "    return {**state, \"city\": city, \"fact\": fact}\n",
    "\n",
    "def call_weather_tool(state: State) -> dict:\n",
    "    weather = get_weather(state[\"city\"])\n",
    "    return {\"weather\": weather}\n",
    "\n",
    "def call_fact_tool(state: State) -> dict:\n",
    "    fact = get_fact(state[\"city\"])\n",
    "    return {\"fact\": fact}\n",
    "\n",
    "def summarize(state: State) -> State:\n",
    "    prompt = f\"\"\"You are a helpful assistant.\n",
    "You were asked: '{state['user_query']}'\n",
    "\n",
    "Here is the weather report: {state['weather']}\n",
    "Here is a historical fact: {state['fact']}\n",
    "\n",
    "Give a friendly summary in 1-2 sentences.\"\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "    return {**state, \"final_summary\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f0fc78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ§© Build the LangGraph\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"extract_city\", RunnableLambda(extract_city))\n",
    "builder.add_node(\"fetch_weather\", RunnableLambda(call_weather_tool))\n",
    "builder.add_node(\"fetch_fact\", RunnableLambda(call_fact_tool))\n",
    "builder.add_node(\"summarize_all\", RunnableLambda(summarize))\n",
    "\n",
    "builder.set_entry_point(\"extract_city\")\n",
    "builder.add_edge(\"extract_city\", \"fetch_weather\")\n",
    "builder.add_edge(\"fetch_weather\", \"fetch_fact\")\n",
    "builder.add_edge(\"fetch_fact\", \"summarize_all\")\n",
    "builder.add_edge(\"summarize_all\", END)\n",
    "\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d0f1129f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted city: Pasadena, fact: What universities are in the city?\n",
      "The current temperature in Pasadena is 26.1Â°C. Pasadena is a vibrant city in Los Angeles County, known for its cultural significance and historical charm.\n"
     ]
    }
   ],
   "source": [
    "# ðŸš€ Run the assistant\n",
    "user_input = \"What is the temperature in Pasadena? What universities are in the city?\"\n",
    "initial_state = {\"user_query\": user_input}\n",
    "\n",
    "result = graph.invoke(initial_state)\n",
    "print(result[\"final_summary\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
